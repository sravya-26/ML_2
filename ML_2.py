# -*- coding: utf-8 -*-
"""hw2_Koyi_Sravya.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AG-6VydsXF39m3WFuJgMAHA_q6SPIXca
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.impute import SimpleImputer
import numpy as np

data = pd.read_csv('http://jse.amstat.org/v19n3/decock/AmesHousing.txt', sep='\t')  # Replace with actual dataset path

features = ['Overall Qual', 'Overall Cond', 'Gr Liv Area', 'Street', 'Central Air',
            'Total Bsmt SF', 'BsmtFin SF 1', 'BsmtFin SF 2', '1st Flr SF',
            '2nd Flr SF', 'Bedroom AbvGr', 'Wood Deck SF', 'Mo Sold',
            'Yr Sold', 'Pool Area']
X = data[features]
y = data['SalePrice']

X = pd.get_dummies(X, columns=['Street', 'Central Air'], drop_first=True)

imputer = SimpleImputer(strategy='mean')
X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)
rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))

print(f"Training RMSE: {rmse_train}")
print(f"Testing RMSE: {rmse_test}")

import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import LeaveOneOut
from sklearn.metrics import accuracy_score

X_train = np.loadtxt('../heart_trainSet.txt', delimiter=',')
y_train = np.loadtxt('../heart_trainLabels.txt')
X_test = np.loadtxt('../heart_testSet.txt', delimiter=',')

y_train = y_train.ravel()

loo = LeaveOneOut()
errors = []
k_range = range(1, 11)

for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    error_sum = 0
    for train_idx, val_idx in loo.split(X_train):
        knn.fit(X_train[train_idx], y_train[train_idx])
        y_pred = knn.predict(X_train[val_idx])
        error_sum += np.mean(y_pred != y_train[val_idx])
    avg_error = error_sum / len(X_train)
    errors.append(avg_error)
    print(f'k={k}, LOOCV error: {avg_error}')

best_k_index = errors.index(min(errors))

best_k = k_range[best_k_index]
print(f"Best k: {best_k}")

y_test_pred = knn_best.predict(X_test)
print(f'Predicted labels for test data: {y_test_pred}')

import numpy as np
import matplotlib.pyplot as plt
import datetime
from sklearn.datasets import load_svmlight_file
from sklearn.linear_model import Ridge, Lasso

X_train, y_train = load_svmlight_file("../E2006_tfidf_train")
X_train = X_train[:, :10000]
X_test, y_test = load_svmlight_file("../E2006_tfidf_test")
X_test = X_test[:, :10000]
print("Data successfully loaded")

lambda_value = 0.1
iterations = 100

# Lasso regression implementation
print("***Lasso Regression***")
lasso_model = Lasso(alpha=lambda_value / X_train.shape[0], max_iter=iterations)
lasso_start = datetime.datetime.now()
lasso_model.fit(X_train, y_train)
lasso_end = datetime.datetime.now()
print("Lasso took: " + str(lasso_end - lasso_start))
print("Lasso number of non-zero coefficients: " + str(np.sum(lasso_model.coef_ != 0)))
print("Lasso Train RMSE: " + str(np.sqrt(np.mean(np.square(lasso_model.predict(X_train) - y_train)))))
print("Lasso Test RMSE: " + str(np.sqrt(np.mean(np.square(lasso_model.predict(X_test) - y_test)))))

# Ridge regression implementation
print("***Ridge Regression***")
ridge_model = Ridge(alpha=lambda_value, solver='lsqr', max_iter=iterations)
ridge_start = datetime.datetime.now()
ridge_model.fit(X_train, y_train)
ridge_end = datetime.datetime.now()
print("Ridge took: " + str(ridge_end - ridge_start))
print("Ridge number of non-zero coefficients: " + str(np.sum(ridge_model.coef_ != 0)))
print("Ridge Train RMSE: " + str(np.sqrt(np.mean(np.square(ridge_model.predict(X_train) - y_train)))))
print("Ridge Test RMSE: " + str(np.sqrt(np.mean(np.square(ridge_model.predict(X_test) - y_test)))))

# Testing multiple lambda values for both Lasso and Ridge
lambda_values = [1e-10, 1e-5, 1e-3, 1e-2, 0.1, 1, 1e2, 1e3, 1e4]

train_rmse_lasso = []
test_rmse_lasso = []
train_rmse_ridge = []
test_rmse_ridge = []
nonzero_lasso = []
nonzero_ridge = []

for lam in lambda_values:
    lasso_model = Lasso(alpha=lam / X_train.shape[0], max_iter=iterations)
    lasso_model.fit(X_train, y_train)
    train_rmse_lasso.append(np.sqrt(np.mean(np.square(lasso_model.predict(X_train) - y_train))))
    test_rmse_lasso.append(np.sqrt(np.mean(np.square(lasso_model.predict(X_test) - y_test))))
    nonzero_lasso.append(np.sum(lasso_model.coef_ != 0))

    ridge_model = Ridge(alpha=lam, solver='lsqr', max_iter=iterations)
    ridge_model.fit(X_train, y_train)
    train_rmse_ridge.append(np.sqrt(np.mean(np.square(ridge_model.predict(X_train) - y_train))))
    test_rmse_ridge.append(np.sqrt(np.mean(np.square(ridge_model.predict(X_test) - y_test))))
    nonzero_ridge.append(np.sum(ridge_model.coef_ != 0))

# Plotting the results
plt.figure(figsize=(12, 5))

# RMSE vs Lambda values
plt.subplot(1, 2, 1)
plt.semilogx(lambda_values, train_rmse_lasso, label='Lasso Train RMSE')
plt.semilogx(lambda_values, test_rmse_lasso, label='Lasso Test RMSE')
plt.semilogx(lambda_values, train_rmse_ridge, label='Ridge Train RMSE')
plt.semilogx(lambda_values, test_rmse_ridge, label='Ridge Test RMSE')
plt.xlabel('Lambda')
plt.ylabel('RMSE')
plt.title('RMSE vs Lambda')
plt.legend()

# Number of non-zero coefficients vs Lambda values
plt.subplot(1, 2, 2)
plt.semilogx(lambda_values, nonzero_lasso, label='Lasso Non-zero Coefficients')
plt.semilogx(lambda_values, nonzero_ridge, label='Ridge Non-zero Coefficients')
plt.xlabel('Lambda')
plt.ylabel('Number of Non-zero Coefficients')
plt.title('Non-zero Coefficients vs Lambda')
plt.legend()

plt.tight_layout()
plt.show()